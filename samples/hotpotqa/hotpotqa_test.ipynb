{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from grammarflow import *\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self):\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        )\n",
    "\n",
    "    def invoke(self, config: dict):\n",
    "        with PromptContextManager(config) as filled_prompt:\n",
    "            return self.request(filled_prompt, temperature=0.01)\n",
    "\n",
    "    def __call__(self, prompt, temperature=0.2, context=None):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    thought: str = Field(..., description=\"Concisely describe the \")\n",
    "    action: str = Field(..., description=\"You only have 3 options: search | lookup | finish\")\n",
    "    action_input: str = Field(..., description=\"Your input to the above action.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_previous_interaction(id_): return id_ > 1\n",
    "\n",
    "def make_prompt(): \n",
    "  prompt = PromptBuilder() \n",
    "  prompt.add_section(\n",
    "    text=\"\"\"\n",
    "  Goal: {question}\n",
    "\n",
    "  Your goal is to solve the above QA task in steps. First, think about what information you need to answer the question. \n",
    "  Use `search` to get the information you need. This needs a single keyword or noun as input. If it can't find anything, itll give alternate keywords. You can find them in your thinking history below, use them to search again. \n",
    "  Use `lookup` to find more information from the paragraph returned by search. This matches the action_input you give to setences in search. \n",
    "  Use `finish` to return your final complete answer as input field. Use this if you believe you have enough information to completely answer the task.\"\"\",\n",
    "    placeholders=[\"question\"]\n",
    "  ) \n",
    "  prompt.add_section(\n",
    "    define_grammar=True\n",
    "  ) \n",
    "  prompt.add_section(\n",
    "    text=\"\\nExample thinking process:{example}\\n\", \n",
    "    placeholders=[\"example\"]\n",
    "  )\n",
    "  prompt.add_section(\n",
    "    text=\"Create the next Step using the information available you to below.\\n\",\n",
    "  )\n",
    "  prompt.add_section(\n",
    "    text=\"DO NOT REPEAT THOUGHTS OR ACTIONS FROM YOUR PAST. ENSURE EACH STEP IS UNIQUE. Below is the history of your thinking process and corresponding observations.\\n{history}\\n\",\n",
    "    placeholders=[\"history\"],\n",
    "    enable_on=check_previous_interaction\n",
    "  ) \n",
    "  return prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikienv, wrappers\n",
    "env = wikienv.WikiEnv()\n",
    "env = wrappers.HotPotQAWrapper(env, split=\"dev\")\n",
    "env = wrappers.LoggingWrapper(env)\n",
    "example = wrappers.EXAMPLE\n",
    "\n",
    "def step(env, action):\n",
    "    attempts = 0\n",
    "    while attempts < 10:\n",
    "        try:\n",
    "            return env.step(action)\n",
    "        except requests.exceptions.Timeout:\n",
    "            attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webthink(idx=None, env=env, to_print=False): \n",
    "  \n",
    "  def log(st, st_=None): \n",
    "    if to_print: \n",
    "      if st_: print(st, st_)\n",
    "      else: print(st)\n",
    "\n",
    "  # Initializing Stateful vars\n",
    "  thought = None \n",
    "  action = None\n",
    "  observation = None\n",
    "  id_ = 1\n",
    "  history, history_ = {}, None\n",
    "\n",
    "  # Initializing question\n",
    "  question = env.reset(idx=idx)\n",
    "  print('Question: ', question)\n",
    "\n",
    "  for i in range(10):\n",
    "    if history:\n",
    "      history_ = \"\\n\".join([f\"Thought {id_}: {value['thought']}\\nAction {id_}: {value['action']}\\nAction_Input {id_}: {value['action_input']}\\nObservation {id_}: {value['observation']}\" for id_, value in history.items()])\n",
    "\n",
    "    with Constrain(make_prompt()) as manager: \n",
    "      manager.set_config(\n",
    "        format='xml'\n",
    "      ) \n",
    "      manager.format_prompt(\n",
    "        placeholders={ \n",
    "          \"question\": question,\n",
    "          'example': example, \n",
    "          \"history\": history_\n",
    "        }, \n",
    "        grammars=[{\n",
    "          'description': 'Your thinking state:', \n",
    "          'model': Step\n",
    "        }], \n",
    "        enable_on={\n",
    "          'id_':id_ \n",
    "        }\n",
    "      ) \n",
    "      \n",
    "      response = llm(manager.prompt, temperature=0.01)\n",
    "      log(response)\n",
    "      response = manager.parse(response)  \n",
    "      log('---------------')\n",
    "\n",
    "      thought = response.Step.thought \n",
    "      action = response.Step.action\n",
    "      action_input = response.Step.action_input\n",
    "\n",
    "    observation, r, done, info = step(env, f\"{action}[{action_input}]\")\n",
    "    observation = observation.replace(\"\\\\n\", \" \")\n",
    "\n",
    "    log('--------------------------')\n",
    "    log('---------------')\n",
    "    log('Prompt:', manager.prompt)\n",
    "    log('---------------')\n",
    "    log('---------------')\n",
    "    print('Step {}'.format(id_))\n",
    "    log('Thought:', thought)\n",
    "    log('Action:', action)\n",
    "    log('Action Input:', action_input)\n",
    "    log('Observation:', observation)\n",
    "    log('--------------------------')\n",
    "    \n",
    "    history[id_] = { \n",
    "      \"thought\": thought, \n",
    "      \"action\": action, \n",
    "      \"action_input\": action_input, \n",
    "      \"observation\": observation\n",
    "    }\n",
    "    id_ += 1\n",
    "    if done: \n",
    "      final = action_input\n",
    "      break \n",
    "\n",
    "  if not done:\n",
    "      final = \"Failed\"\n",
    "      observation, r, done, info = step(env, \"finish[]\")\n",
    "\n",
    "  return final, info['gt_answer'], id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(7405))\n",
    "random.Random(233).shuffle(idxs)\n",
    "\n",
    "errors = []\n",
    "logs = {} \n",
    "old_time = time.time()\n",
    "for i in idxs[:5]:\n",
    "    try: \n",
    "        action_input, answer, id_ = webthink(i, env)\n",
    "        logs[i] = {\n",
    "            'action_input': action_input,\n",
    "            'answer': answer, \n",
    "            'steps': id_\n",
    "        }\n",
    "        print('Answer:', answer)\n",
    "        print('Action Input:', action_input)\n",
    "        print('-----------')\n",
    "        print()\n",
    "    except: \n",
    "        errors += [i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
